{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab6304a1-cfa0-4cd1-9656-7cd40e3141a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================== Permutation Feature Importance Analysis =====================\n",
      "Baseline r2 score: 0.741859\n",
      "\n",
      "Feature Importance (Higher value = more important):\n",
      "PCA Component 1: Mean Importance = 0.141933 (Standard Deviation = 0.040137)\n",
      "PCA Component 2: Mean Importance = 0.780052 (Standard Deviation = 0.079832)\n",
      "PCA Component 3: Mean Importance = 0.093063 (Standard Deviation = 0.017259)\n",
      "PCA Component 4: Mean Importance = 0.007797 (Standard Deviation = 0.007750)\n",
      "PCA Component 5: Mean Importance = 0.015848 (Standard Deviation = 0.004200)\n",
      "PCA Component 6: Mean Importance = 0.012564 (Standard Deviation = 0.003577)\n",
      "\n",
      "üìÅ Results exported to: RF_PCA_6D_Results-IMS-Permutation_Feature_Importance.xlsx\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import csv\n",
    "import sys\n",
    "from io import StringIO\n",
    "\n",
    "\n",
    "original_stdout = sys.stdout\n",
    "\n",
    "sys.stdout = StringIO()\n",
    "\n",
    "np.random.seed(42)\n",
    "GAP_THRESHOLD = 0.15\n",
    "N_REPEATS = 10\n",
    "SCORING_METRIC = 'r2'\n",
    "\n",
    "\n",
    "pattern = []\n",
    "with open('4-pattern1.csv', 'r', encoding='utf-8-sig') as fhd:\n",
    "    fhd_csv = csv.reader(fhd)\n",
    "    for line in fhd_csv:\n",
    "        pattern.append(line)\n",
    "pattern = np.array(pattern, dtype='float64')\n",
    "\n",
    "\n",
    "pattern = np.where(np.isinf(pattern), np.nan, pattern)\n",
    "pattern = np.nan_to_num(pattern, nan=np.nanmean(pattern) if not np.isnan(np.nanmean(pattern)) else 0)\n",
    "\n",
    "min_vals = np.min(pattern, axis=0)\n",
    "max_vals = np.max(pattern, axis=0)\n",
    "range_vals = np.where(max_vals - min_vals == 0, 1, max_vals - min_vals)\n",
    "pattern_normalized = (pattern - min_vals) / range_vals\n",
    "\n",
    "scaler = StandardScaler()\n",
    "pattern_scaled = scaler.fit_transform(pattern_normalized)\n",
    "\n",
    "\n",
    "label_data = []\n",
    "with open('output-IMS10.csv', 'r', encoding='utf-8-sig') as fhl:\n",
    "    fhl_csv = csv.reader(fhl)\n",
    "    for line in fhl_csv:\n",
    "        label_data.append(line)\n",
    "label_data = np.array(label_data, dtype='float64')\n",
    "\n",
    "groups = label_data[:, 0]\n",
    "label_c = label_data[:, 1]\n",
    "label_c = np.exp(label_c)\n",
    "\n",
    "\n",
    "unique_groups = np.unique(groups)\n",
    "train_groups, test_groups = train_test_split(\n",
    "    unique_groups,\n",
    "    test_size=99/491,\n",
    "    random_state=42\n",
    ")\n",
    "train_mask = np.isin(groups, train_groups)\n",
    "test_mask = np.isin(groups, test_groups)\n",
    "\n",
    "X_train_raw = pattern_scaled[train_mask]\n",
    "y_train = label_c[train_mask]\n",
    "X_test_raw = pattern_scaled[test_mask]\n",
    "y_test = label_c[test_mask]\n",
    "\n",
    "\n",
    "pca = PCA(n_components=12)\n",
    "X_train_pca_all = pca.fit_transform(X_train_raw)\n",
    "X_test_pca_all = pca.transform(X_test_raw)\n",
    "\n",
    "X_train_pca = X_train_pca_all[:, :6]\n",
    "X_test_pca = X_test_pca_all[:, :6]\n",
    "\n",
    "\n",
    "def mean_relative_error(y_true, y_pred):\n",
    "    mask = y_true != 0\n",
    "    if np.sum(mask) == 0:\n",
    "        return 0.0\n",
    "    return np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask]))\n",
    "\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mre = mean_relative_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    return {\n",
    "        'mae': mae,\n",
    "        'mse': mse,\n",
    "        'rmse': rmse,\n",
    "        'mre': mre,\n",
    "        'r2': r2\n",
    "    }\n",
    "\n",
    "\n",
    "def permutation_feature_importance(model, X, y, n_repeats=10, scoring='r2'):\n",
    "    y_pred = model.predict(X)\n",
    "    if scoring == 'r2':\n",
    "        baseline_score = r2_score(y, y_pred)\n",
    "    elif scoring == 'mae':\n",
    "        baseline_score = -mean_absolute_error(y, y_pred)\n",
    "    elif scoring == 'mse':\n",
    "        baseline_score = -mean_squared_error(y, y_pred)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported scoring metric: {scoring}\")\n",
    "    \n",
    "    n_features = X.shape[1]\n",
    "    importances = np.zeros((n_repeats, n_features))\n",
    "    \n",
    "    for i in range(n_repeats):\n",
    "        for j in range(n_features):\n",
    "            X_permuted = X.copy()\n",
    "            np.random.shuffle(X_permuted[:, j])\n",
    "            \n",
    "            y_pred_permuted = model.predict(X_permuted)\n",
    "            if scoring == 'r2':\n",
    "                score = r2_score(y, y_pred_permuted)\n",
    "            elif scoring == 'mae':\n",
    "                score = -mean_absolute_error(y, y_pred_permuted)\n",
    "            elif scoring == 'mse':\n",
    "                score = -mean_squared_error(y, y_pred_permuted)\n",
    "            \n",
    "            importances[i, j] = baseline_score - score\n",
    "    \n",
    "    mean_importances = np.mean(importances, axis=0)\n",
    "    std_importances = np.std(importances, axis=0)\n",
    "    \n",
    "    return mean_importances, std_importances, baseline_score\n",
    "\n",
    "\n",
    "best_params = {\n",
    "    'n_estimators': 50,\n",
    "    'max_depth': 20,\n",
    "    'min_samples_split': 10,\n",
    "    'min_samples_leaf': 2,\n",
    "    'max_features': 'sqrt'\n",
    "}\n",
    "\n",
    "model = RandomForestRegressor(\n",
    "    n_estimators=best_params['n_estimators'],\n",
    "    max_depth=best_params['max_depth'],\n",
    "    min_samples_split=best_params['min_samples_split'],\n",
    "    min_samples_leaf=best_params['min_samples_leaf'],\n",
    "    max_features=best_params['max_features'],\n",
    "    bootstrap=True,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(\n",
    "    X_train_pca, y_train, \n",
    "    test_size=0.2, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "model.fit(X_tr, y_tr)\n",
    "\n",
    "\n",
    "y_tr_pred = model.predict(X_tr)\n",
    "y_val_pred = model.predict(X_val)\n",
    "y_train_pred = model.predict(X_train_pca)\n",
    "y_test_pred = model.predict(X_test_pca)\n",
    "\n",
    "tr_metrics = calculate_metrics(y_tr, y_tr_pred)\n",
    "val_metrics = calculate_metrics(y_val, y_val_pred)\n",
    "train_metrics = calculate_metrics(y_train, y_train_pred)\n",
    "test_metrics = calculate_metrics(y_test, y_test_pred)\n",
    "\n",
    "train_val_gap = abs(train_metrics['r2'] - val_metrics['r2'])\n",
    "train_test_gap = abs(train_metrics['r2'] - test_metrics['r2'])\n",
    "\n",
    "is_valid = (train_val_gap < GAP_THRESHOLD) and (train_test_gap < GAP_THRESHOLD)\n",
    "\n",
    "# Final model training\n",
    "final_model = RandomForestRegressor(**best_params, bootstrap=True, random_state=42, n_jobs=-1)\n",
    "final_model.fit(X_train_pca, y_train)\n",
    "final_y_train_pred = final_model.predict(X_train_pca)\n",
    "final_y_test_pred = final_model.predict(X_test_pca)\n",
    "\n",
    "sys.stdout = original_stdout\n",
    "\n",
    "\n",
    "print(\"\\n===================== Permutation Feature Importance Analysis =====================\")\n",
    "importances, importances_std, baseline_score = permutation_feature_importance(\n",
    "    final_model, X_test_pca, y_test, \n",
    "    n_repeats=N_REPEATS, \n",
    "    scoring=SCORING_METRIC\n",
    ")\n",
    "\n",
    "feature_names = [f'PCA Component {i+1}' for i in range(len(importances))]\n",
    "\n",
    "print(f\"Baseline {SCORING_METRIC} score: {baseline_score:.6f}\")\n",
    "print(\"\\nFeature Importance (Higher value = more important):\")\n",
    "for name, imp, std in zip(feature_names, importances, importances_std):\n",
    "    print(f\"{name}: Mean Importance = {imp:.6f} (Standard Deviation = {std:.6f})\")\n",
    "\n",
    "pca_pred = np.full(len(pattern_scaled), np.nan)\n",
    "pca_pred[train_mask] = final_y_train_pred\n",
    "pca_pred[test_mask] = final_y_test_pred\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    \"Original_Index\": range(1, len(pattern_scaled)+1),\n",
    "    \"PCA_Dimensions\": 6,\n",
    "    \"Group\": groups,\n",
    "    \"True_Label\": label_c,\n",
    "    \"Dataset\": np.where(np.isin(groups, train_groups), \"Training Set\", \"Test Set\"),\n",
    "    \"Predicted_Label\": pca_pred\n",
    "})\n",
    "\n",
    "summary_df = pd.DataFrame({\n",
    "    \"PCA_Components\": [6],\n",
    "    \"Best_Params\": [str(best_params)],\n",
    "    \"Train_R2\": [round(train_metrics['r2'], 6)],\n",
    "    \"Train_MAE\": [round(train_metrics['mae'], 6)],\n",
    "    \"Train_MSE\": [round(train_metrics['mse'], 6)],\n",
    "    \"Train_MRE\": [round(train_metrics['mre'], 6)],\n",
    "    \"Train_RMSE\": [round(train_metrics['rmse'], 6)],\n",
    "    \"Val_R2\": [round(val_metrics['r2'], 6)],\n",
    "    \"Val_MAE\": [round(val_metrics['mae'], 6)],\n",
    "    \"Val_MSE\": [round(val_metrics['mse'], 6)],\n",
    "    \"Val_MRE\": [round(val_metrics['mre'], 6)],\n",
    "    \"Val_RMSE\": [round(val_metrics['rmse'], 6)],\n",
    "    \"Test_R2\": [round(test_metrics['r2'], 6)],\n",
    "    \"Test_MAE\": [round(test_metrics['mae'], 6)],\n",
    "    \"Test_MSE\": [round(test_metrics['mse'], 6)],\n",
    "    \"Test_MRE\": [round(test_metrics['mre'], 6)],\n",
    "    \"Test_RMSE\": [round(test_metrics['rmse'], 6)],\n",
    "    \"Train_Val_Gap\": [round(train_val_gap, 6)],\n",
    "    \"Train_Test_Gap\": [round(train_test_gap, 6)],\n",
    "    \"Is_Valid\": [is_valid]\n",
    "})\n",
    "\n",
    "importance_df = pd.DataFrame({\n",
    "    \"Feature_Name\": feature_names,\n",
    "    \"Mean_Importance\": [round(imp, 6) for imp in importances],\n",
    "    \"Importance_Std\": [round(std, 6) for std in importances_std],\n",
    "    \"Baseline_Score\": [round(baseline_score, 6)] * len(importances),\n",
    "    \"Scoring_Metric\": [SCORING_METRIC] * len(importances),\n",
    "    \"Permutation_Repeats\": [N_REPEATS] * len(importances)\n",
    "})\n",
    "\n",
    "with pd.ExcelWriter('RF_PCA_6D_Results-IMS-Permutation_Feature_Importance.xlsx', engine='openpyxl') as writer:\n",
    "    summary_df.to_excel(writer, sheet_name='PCA_Performance_Summary', index=False)\n",
    "    results_df.to_excel(writer, sheet_name='Full_Dimension_Predictions', index=False)\n",
    "    importance_df.to_excel(writer, sheet_name='Permutation_Feature_Importance', index=False)\n",
    "\n",
    "print(f\"\\nüìÅ Results exported to: RF_PCA_6D_Results-IMS-Permutation_Feature_Importance.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5e9fa5-9f8c-431e-99e0-a63490646b5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
